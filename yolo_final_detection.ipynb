{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "890c17f8-fe3c-4a2b-a965-7a91c49b520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef640583-6f0c-4ec8-bdb2-3b8d246cb0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobile(E-waste)', 'E-waste', 'plastic(Non E waste)', 'keyboard(E-waste)', 'laptop(E-waste)', 'headphones(E-waste)', 'television(E-waste)', 'mouse(E-waste)', 'battery(E-waste)', 'printer(E-waste)', 'charger(E-waste)', 'microwave(E-waste)', 'vegetable_peel(not a E-waste)', 'paper(Non E-waste)', 'fruit(not a E-waste)', 'egg(not a E-waste)', 'vegetablel(not a E-waste)', 'food(not a E-waste)', 'wires(E-waste)', 'paper(not a E-waste)']\n"
     ]
    }
   ],
   "source": [
    "# load YAML\n",
    "with open('data.yaml',mode='r') as f:\n",
    "    data_yaml = yaml.load(f,Loader=SafeLoader)\n",
    "    \n",
    "labels = data_yaml['names']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b52c5c41-cb6a-4943-84e6-98976666d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading yolo model\n",
    "yolo = cv2.dnn.readNetFromONNX('./Model-20240415T134521Z-001/Model/weights/best.onnx')\n",
    "yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1b48edc-b984-4863-b875-7150f75f7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the image\n",
    "img = cv2.imread('nokia.jpeg')\n",
    "image = img.copy()\n",
    "row, col, d = image.shape\n",
    "\n",
    "\n",
    "# getting the YOLO prediction from the the image\n",
    "# step-1 converting image into square image (array)\n",
    "max_rc = max(row,col)\n",
    "input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "input_image[0:row,0:col] = image\n",
    "# step-2: get prediction from square array\n",
    "INPUT_WH_YOLO = 640\n",
    "blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "yolo.setInput(blob)\n",
    "preds = yolo.forward() # detection or prediction from YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7722afd7-1e5a-4e0b-85c2-36f079794ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25200, 25)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "da56c5c0-d0f8-4d74-b32e-60eaf6d13310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: mobile(E-waste)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "detections = preds[0]\n",
    "boxes = []\n",
    "confidences = []\n",
    "classes = []\n",
    "\n",
    "# width and height of the image (input_image)\n",
    "image_w, image_h = input_image.shape[:2]\n",
    "x_factor = image_w / INPUT_WH_YOLO\n",
    "y_factor = image_h / INPUT_WH_YOLO\n",
    "\n",
    "# Iterate through detections\n",
    "for detection in detections:\n",
    "    confidence = detection[4]  # Confidence of detecting an object\n",
    "    if confidence > 0.1:  # Adjust the confidence threshold as needed\n",
    "        class_scores = detection[5:] if len(detection) >= 6 else []\n",
    "        if len(class_scores) > 0:  # Check if class_scores has any elements\n",
    "            class_score = np.max(class_scores)\n",
    "            class_id = np.argmax(class_scores)\n",
    "            if class_score > 0.25:\n",
    "                cx, cy, w, h = detection[0:4]\n",
    "                # Construct bounding box from four values: left, top, width, and height\n",
    "                left = int((cx - 0.5 * w) * x_factor)\n",
    "                top = int((cy - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = [left, top, width, height]  # No need to convert to numpy array\n",
    "                # Append values into the lists\n",
    "                confidences.append(float(confidence))  # Ensure confidence is float\n",
    "                boxes.append(box)\n",
    "                classes.append(class_id)\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "boxes_np = np.array(boxes)\n",
    "confidences_np = np.array(confidences)\n",
    "\n",
    "# Non-Maximum Suppression (NMS)\n",
    "if len(boxes_np) > 0:\n",
    "    indices = cv2.dnn.NMSBoxes(boxes_np.tolist(), confidences_np.tolist(), 0.25, 0.45)\n",
    "    indices = indices.flatten()\n",
    "\n",
    "    # Drawing bounding boxes and printing names of detected objects\n",
    "    for ind in indices:\n",
    "        if ind < len(classes):\n",
    "            # Extract bounding box\n",
    "            x, y, w, h = boxes_np[ind]\n",
    "            bb_conf = int(confidences_np[ind] * 100)\n",
    "            class_id = classes[ind]\n",
    "\n",
    "            # Check if the class_id is within the range of labels list\n",
    "            if class_id < len(labels):\n",
    "                class_name = labels[class_id]\n",
    "                # Print the name of the detected object\n",
    "                print(\"Detected:\", class_name)\n",
    "\n",
    "                text = f'{class_name}: {bb_conf}%'\n",
    "\n",
    "                cv2.rectangle(input_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.rectangle(input_image, (x, y - 30), (x + w, y), (255, 255, 255), -1)\n",
    "\n",
    "                cv2.putText(input_image, text, (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 0, 0), 1)\n",
    "            else:\n",
    "                print(f\"Class ID {class_id} is out of range for labels list\")\n",
    "        else:\n",
    "            print(f\"Index {ind} is out of range for classes list\")\n",
    "\n",
    "# Show the image with bounding boxes and class names\n",
    "cv2.imshow(\"Image\", input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8431118-6d63-4877-adad-515d3852eb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
